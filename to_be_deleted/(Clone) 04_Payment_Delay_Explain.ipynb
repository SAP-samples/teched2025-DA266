{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "263402ab-2336-474c-913c-6949d60e5e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Payment Delay Explain\n",
    "While [SHapley Additive exPlanations (SHAP) values](https://shap.readthedocs.io/en/latest/index.html) offer a powerful explanation of the prediction for data scientists, they can be difficult to interpret directly for business users. In this notebook we will use SAP AI Foundation services for Large Language Model (LLM) to intepret the prediction results in natural language. \n",
    "\n",
    "We demonstrate this through the example of [SAP AI Core Orchestration Service](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/orchestration-8d022355037643cebf775cd3bf662cc5?locale=en-US), which provides harmonized access to a wide range of frontier AI / LLM models. The orchestration service will be exposed as an MLflow model, for fully integrated downstream processing in SAP Databricks.\n",
    "\n",
    "These are the steps for the exercise:\n",
    "\n",
    "1. Install and import packages\n",
    "2. Load prediction data and SHAP Values\n",
    "3. Define Explanation Model class\n",
    "4. Run Explanation Model\n",
    "5. Validate explanation output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a8684e8-ae20-4d64-ac31-892ef3dce4c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prerequisites\n",
    "> [IMPORTANT]\n",
    "> This step has already been done by the administrator. However, if you need to do it on you own you can follow the steps described here to create a secret scope for secure access of SAP Cloud SDK for AI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "950cc051-3fc7-48cc-9748-c42c321d14cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To securely store and access SAP AI Core credentials from within SAP Databricks, create a Databricks secret(refer to [Databricks documentation on creating secret scopes](https://docs.databricks.com/aws/en/security/secrets)). \n",
    "\n",
    "Then, store the following access parameters as case-sensitive key-value pairs within this scope, as they are [defined in the documentation of the generative AI SDK](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/README_sphynx.html#environment-variables):\n",
    "\n",
    "- AICORE_BASE_URL\n",
    "- AICORE_AUTH_URL\n",
    "- AICORE_CLIENT_ID\n",
    "- AICORE_CLIENT_SECRET\n",
    "- AICORE_RESOURCE_GROUP\n",
    "\n",
    "Setting these credentials as environment variables allows the SAP Cloud SDK for AI (Python) to seamlessly authenticate and interact with the SAP AI Core orchestration service within the Databricks runtime. The SAP Cloud SDK for AI (Python) automatically manages the configuration and deployment of orchestration service endpoints and the desired Large Language Models (LLMs) upon initial use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a739e220-446b-4ca2-b968-2ab414624101",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Install and import packages\n",
    "In the next few cells, we will install and import the required packages. Please make sure, that we use the right versions of the libraries. While SAP AI Core capabilities are exposed via a REST API (see the [documentation on the SAP Business Accelerator Hub](https://api.sap.com/package/SAPAICore/rest)), this guide leverages the SAP Cloud SDK for AI (Python) to simplify consumption within Databricks notebooks. This SDK [sap-ai-sdk-gen](https://pypi.org/project/sap-ai-sdk-gen/) is free for download from PyPI and is documented on the [SAP Help Portal](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66b87703-9de9-478a-b310-e6ab0363cc95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install \"sap-ai-sdk-gen[all]\"\n",
    "%pip install \"mlflow[databricks]==3.1.3\"\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "629c7fce-a5f2-493b-b91a-8f3f3c05c130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import datetime, time\n",
    "from typing import List, Optional, Iterable, Union, Dict, Any\n",
    "import httpx\n",
    "import mlflow\n",
    "import gen_ai_hub as gen_ai_hub\n",
    "\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.exceptions  import OrchestrationError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c406a7cf-e798-4e29-88df-c5eb91137806",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Set Parameters\n",
    "Please replace the values `<CATALOG_NAME>` and `<SCHEMA_NAME>` with the specific values that match our use case and group. You can find the correct names by checking the **Unity Catalog** and look for the specific catalog and schema names: `uc_XXX`, `grpX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "823469f8-a96f-4ea5-ab3e-106342c19d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- CREATE CATALOG IF NOT EXISTS <CATALOG_NAME>;\n",
    "SET CATALOG uc_delayed_payments;\n",
    "CREATE SCHEMA IF NOT EXISTS grp01;\n",
    "USE SCHEMA grp01;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddaca63b-d9d1-4504-9d60-f17ecd8f05e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SECRET_SCOPE = \"aicore_service_params\"\n",
    "# single env var provided to model\n",
    "os.environ[\"SECRET_SCOPE\"] = SECRET_SCOPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6aeb0aa6-8b2c-438c-a53c-b693f765f695",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Load prediction data and SHAP Values\n",
    "Replace `<DELAY_PREDICTION_SHAP>` with the name of the delay prediction result table from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abb64207-f235-4485-a1e4-fb99ca1fd093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap_table_df = spark.read.table(\"delay_prediction_shap\")\n",
    "# display(shap_table_df.limit(10))\n",
    "print(f\"rows: {shap_table_df.count()}, columns: {len(shap_table_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b63834be-e0f6-4844-a64b-09634894abcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Filter on Top 5 payment delay predictions \n",
    "\n",
    "We will use only a subset of the prediction dataset to apply the LLM explanation. For that we create a data smaple of top 5 delays. Replace the `<LIMIT>` with the value `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f354083c-1c4c-40e8-9bcb-143a0c131c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered_shap_table_df = shap_table_df.orderBy(\"delay_prediction\", ascending=False).limit(5).toPandas()\n",
    "display(filtered_shap_table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d74eba97-1ae0-4ce4-a7a6-6fc03cb5561e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e11922eb-8ead-4aa4-bbb6-b6ae06113efb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Define Explanation Model class\n",
    "\n",
    "In the following we show how the additional capabilities of the SAP AI Core Orchestration Service can be leveraged in combination with MLflow in Databricks to generate our model explanations for the delay prediction. We use the orchestration service of GenAI Hub via the SAP Cloud SDK for AI (Python) as documented [here](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/orchestration-service.html).\n",
    "\n",
    "In our exercise, we use a **GPT-4o-mini** model with a maximum token limit of **1000**. In our example, we directly use Prompt Template of AI Core without the prompt registry functionality.\n",
    "\n",
    "For the integration into MLflow, we provide a custom Python class derived from [mlflow.pyfunc.PythonModel](https://mlflow.org/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.PythonModel). The Python class is elaborated in the following with the methods\n",
    "\n",
    "- **\\__init\\__(…)** to instatiate the class\n",
    "- **load_context(…)** to instantiate the orchestration service\n",
    "- **predict(…)** to generate the verbal explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5c41892-9550-45ac-9bbf-ab3f0fdaf0d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### init(...)\n",
    "For the init function we define in total three different parameters. \n",
    "- llm_model: stores the model name, \n",
    "- max_tokens:  parameter as well as the \n",
    "- orchestration_service: store the orchestration service instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5fffaa6-3610-46cb-a812-5bb85ac2cb2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### load context(...)\n",
    "\n",
    "The load_context method is used to establish the connection to an external service from the MLflow custom class. A detailed explanation of the setup of the mlflow pyfunc PythonModel class can be found under the following [tutorial article](https://www.mlflow.org/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc/part2-pyfunc-components/).\n",
    "\n",
    "\n",
    "\n",
    "Instead of directly consuming a LLM for explanation, we use the orchestration service of the Generative AI Hub because it offers a variety of features such as\n",
    "- the Prompt Registry for the management prompt templates,\n",
    "- the capability to mask personal or enterprise critical information\n",
    "- etc.\n",
    "\n",
    "For that we configure and create an instance of the SAP AI Core OrchestrationService using the following variables:\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6445141d-646b-491d-8ac5-29baa7270e33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Replace the variable `<LLM_MODEL>` with the value `GPT-4o-mini` and the variable `<MAX_TOKENS>` with the value `1000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a7b5006-23fd-4d19-82bd-ed3ef381bc6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the following we demonstrate how the additional capabilities of the orchestration service can be leveraged in combination with MLflow in Databricks to generate our model explanations for the delay prediction. We use the orchestration service of GenAI Hub via the SAP Cloud SDK for AI (Python) as documented [here](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/orchestration-service.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e166ddc-e1a0-4583-80a0-19e5f4a74025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### predict(...)\n",
    "For the predict method, we expect the *model_input* variable which receives the filtered shap values as input.\n",
    "\n",
    "For the overall output generation, we iterate over each individual role of the pandas dataframe. In the very first step, we extract the primary keys to return them in combination with the generated delay_explanation. The variables shap_array as well as the delay_prediction are used to fill the prompt template we used for the orchestration configuration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5560eec-4df9-4d78-bd88-c7260ee46cc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We focus on the five variables with the highest abolute SHAP values, which we filter out by replacing the \n",
    "`<TOP_FEATURES>` with the value `5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1aa493e-77b4-4d9d-a118-fd613a07a391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Once we have prepared the input of our data, we start our MLflow span to log our traces for the individual completion task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b54140d3-2305-432e-8942-f7494b9e934a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from gen_ai_hub.orchestration.models.message import UserMessage\n",
    "import gen_ai_hub\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.message import UserMessage\n",
    "from typing import Dict, Any\n",
    "from mlflow.tracing import set_span_chat_messages\n",
    "\n",
    "class ExplanationModel(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature_descrptions = None\n",
    "        self.key_columns = None\n",
    "        self.llm_model = \"gpt-4o-mini\"\n",
    "        self.max_tokens = 1000\n",
    "        self.orchestration_service = None\n",
    "\n",
    "        # since the model is not saved and loaded, we need to load the context here\n",
    "        self.load_context()\n",
    "\n",
    "\n",
    "    def load_context(self, context={}) -> None:\n",
    "        \"\"\"\n",
    "        Load the context from the mlflow context.\n",
    "        \"\"\"\n",
    "        # get secet scope\n",
    "        secret_scope = os.environ['SECRET_SCOPE']\n",
    "\n",
    "        # set secret values as environment variables\n",
    "        for key in [\"AICORE_CLIENT_ID\", \"AICORE_CLIENT_SECRET\", \"AICORE_AUTH_URL\", \"AICORE_BASE_URL\", \"AICORE_RESOURCE_GROUP\"]:\n",
    "            os.environ[key] = dbutils.secrets.get(scope = secret_scope, key=key)\n",
    "\n",
    "        user_message_content = \"{{?prompt}}\"\n",
    "\n",
    "        orchestration_config = OrchestrationConfig(\n",
    "            template=Template(messages=[UserMessage(user_message_content)]),\n",
    "            llm=LLM(name=self.llm_model, parameters={\"max_tokens\": self.max_tokens})\n",
    "        )\n",
    "        self.orchestration_service = OrchestrationService(config = orchestration_config)\n",
    "\n",
    "    def load_key_column_names(self, key_columns):\n",
    "        self.key_columns = key_columns\n",
    "\n",
    "\n",
    "    def build_prompt(self, row: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        We construct the prompt from \"shap_array\" as a dynamic set of parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        # We focus on the five variables with the highest abolute SHAP values, which we filter out by replacing the <TOP_FEATURES> with the value 5\n",
    "        shap_value_array = sorted( row[\"shap_array\"], key = lambda x: (abs(x[\"shap_value\"])), reverse=True)[:5]\n",
    "\n",
    "        included_feature_number = 5\n",
    "        feature_descriptions_md = \"\"\n",
    "        feature_values_md = \"\"\n",
    "        shap_values_md = \"\"\n",
    "\n",
    "        for i in range(included_feature_number):\n",
    "            shap_array_item = shap_value_array[i]\n",
    "            feature_descriptions_md += f\"- '{shap_array_item['column_name']}': {shap_array_item['column_description']}\\n\"\n",
    "            feature_values_md +=  f\"- Value of '{shap_array_item['column_name']}': {shap_array_item['column_value']}\\n\"\n",
    "            shap_values_md += f\"- SHAP value for '{shap_array_item['column_name']}': {shap_array_item['shap_value']} days\\n\"\n",
    "\n",
    "\n",
    "        prompt = \"You are a data scientist who explains predictions of a business artificial intelligence model.\\n\"\n",
    "        prompt += \"The model predicts the expected delay for a payment.\\n\"\n",
    "\n",
    "        prompt += \"\\nThe following payment attributes are relevant for the prediction:\\n\"\n",
    "        prompt += feature_descriptions_md\n",
    "\n",
    "        prompt += \"\\nValues of these payment attributes:\\n\"\n",
    "        prompt += feature_values_md\n",
    "\n",
    "        prompt += \"\\nSHAP values for the attribute:\\n\"\n",
    "        prompt += shap_values_md\n",
    "\n",
    "        #TODO: add confidence etc\n",
    "\n",
    "        prompt += f\"\\nThe SHAP value for a feature decribes to what amount the predicted delay of {row['delay_prediction']} days deviates from the average value. A negative SHAP value for a feature means that the feature value reduces the prediction below average, while a positive value means that the feature value increases the prediction above average.\\n\"\n",
    "        prompt += \"Your task is to explain this specific prediction in a concise manner to a business person who is not a data scientist and who wants to understand which features are relevant for the prediction.\"\n",
    "        prompt += \" Do not mention the SHAP values in your explanation. You can use the feature values.\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, model_input, params=None):\n",
    "        \"\"\" \n",
    "        Process the model inuput:\n",
    "        Expected input: Pandas DataFrame with \n",
    "        - key columns, with column names as listed in the list 'key_columns'\n",
    "        - columns 'shap_array', where each entry has the key 'column_name', 'column_description', 'column_value', 'shap_value' (all double)\n",
    "        - column 'delay_prediction'\n",
    "        Generated output: Pandas DataFrame with \n",
    "        - key columns,\n",
    "        - column 'delay_prediction' (double), and \n",
    "        - colums 'delay_explanation' (string)\n",
    "        \"\"\"\n",
    "        \n",
    "        model_output = []\n",
    "        rows = json.loads(model_input.to_json(orient='records'))\n",
    "\n",
    "        for row in rows:\n",
    "\n",
    "            row_result = {}\n",
    "            for key in self.key_columns:\n",
    "                row_result[key] = row[key]\n",
    "\n",
    "            row_result[\"delay_prediction\"] = row[\"delay_prediction\"]\n",
    "\n",
    "            template_values = []\n",
    "            prompt = self.build_prompt(row)\n",
    "            template_values.append(TemplateValue(name=\"prompt\", value=prompt))\n",
    "\n",
    "            with mlflow.start_span(name=\"shap_explanation\", span_type=\"LLM\") as span:\n",
    "\n",
    "                span.set_inputs(row)\n",
    "                try:\n",
    "                    orchestrationResponse = self.orchestration_service.run(template_values=template_values)\n",
    "                    orchestration_result = orchestrationResponse.orchestration_result\n",
    "                    \n",
    "                    choice = orchestration_result.choices[0]\n",
    "                    completion = choice.message.content\n",
    "                    row_result[\"delay_explanation\"] = completion\n",
    "                    messages = [{\"role\": message.role.value, \"content\": message.content} for message in orchestrationResponse.module_results.templating]\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": completion})\n",
    "                    set_span_chat_messages(span, messages)\n",
    "                    span.set_attributes({\"model_name\": self.llm_model, \"max_tokens\": self.max_tokens})\n",
    "                    span.set_outputs({\"prompt\": prompt, \"delay_explanation\": completion})\n",
    "\n",
    "                except OrchestrationError as error:\n",
    "                    model_output.append(error.message)\n",
    "                    span.set_outputs({\"ERROR\": error.message})\n",
    "\n",
    "\n",
    "                model_output.append(row_result)\n",
    "        \n",
    "        \n",
    "        pd_model_output = pd.DataFrame.from_records(model_output)\n",
    "        return pd_model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "737e0cc6-1c73-4dc7-921e-c90254911741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Run the explanation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1bbfb35-8efb-4d23-b217-19e1d6bb1cb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be26efac-9008-4b2b-910d-8c5a5567d198",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "key_columns = [\"CompanyCode\", \"AccountingDocument\", \"FiscalYear\", \"AccountingDocumentItem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "096c3768-a4b2-40e1-a767-7444f8f57cf9",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1759236311734}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "explanation_model = ExplanationModel()\n",
    "\n",
    "explanation_model.load_key_column_names(key_columns)\n",
    "# explanation_model.load_feature_decriptions(feature_descrptions)\n",
    "\n",
    "\n",
    "# test prompt generation\n",
    "explanation_output = explanation_model.predict(filtered_shap_table_df)\n",
    "\n",
    "display(explanation_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a171a9d5-9ac1-4f37-923a-61a62bb98028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Validate the explanation output\n",
    "\n",
    "When executed successfully, you should be able to see the MLflow Trace UI. There you will find all logged information well organized for review:\n",
    "1. The _explanation_output_ table\n",
    "    - containing 5 records\n",
    "    - each record has a the column *delay_explanation*, where the LLM result is stored\n",
    "2. The MLflow Trace UI\n",
    "    - The tab _Chat_ contains all the messages we logged during the execution. Here you can find in the `Assistant` section the LLM explanation.\n",
    "    - The tab _Inputs/Outputs contains the Inputs and Outputs for the explanation\n",
    "    - the tab _Attributes_ contains the parameters we set in the explanation model class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97fe848b-9de7-48fe-b81d-17cbfbfc7124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "NOTE:\n",
    "- orchestration **service calls are traced in this experiment** https://dbc-6d11e582-1008.cloud.databricks.com/ml/experiments/139cee9231254a69a1821d60f7bc3504?o=331377520300711&searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D&compareRunsMode=TRACES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffdf1c56-92d1-417c-9205-c1408ad978b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6996363428705479,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) 04_Payment_Delay_Explain",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
