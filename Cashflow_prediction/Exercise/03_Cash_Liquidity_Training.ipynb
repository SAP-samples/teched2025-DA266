{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c85f9a73-59c6-43b5-a976-649c84f43d30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cash Liquidity Training\n",
    "In this notebook we will use the prepared times series data to train a forecasting model for `cashflow`. For that we will work with the [statsforecast](https://nixtlaverse.nixtla.io/statsforecast/index.html) library, which is highly optimized for speed and scalability.\n",
    "\n",
    "This involves in total the following steps for the overall prediction:\n",
    "\n",
    "1. Install and import packages\n",
    "2. Load prepared time series table\n",
    "3. Train forecasting model\n",
    "4. Evaluating the logged performance in mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a9374b4-e697-4e5b-bacf-7de66f29d692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Install and import packages\n",
    "All necessary packages for this notebook are going to be outlined in the following notebook cell. In order to make sure that the results are reproducible, the following packages are going to be installed:\n",
    "- mlflow: Tracking of our ML model\n",
    "- statsforecast:  is a high-performance Python package designed for univariate time series forecasting using statistical and econometric model and is optimized for speed and scalability, making it suitable for both production environments and benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7db6fb6d-c2ca-4295-91b3-b9042a440ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow\n",
    "%pip install statsforecast\n",
    "%pip install mlflavors\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6467884-2a25-49d8-bb20-4e35858fe424",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import ADIDA, AutoARIMA, CrostonOptimized, AutoETS, AutoCES, ARCH, AutoMFLES, AutoTheta\n",
    "from delta import *\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import mlflavors\n",
    "from mlflow.client import MlflowClient\n",
    "from utilsforecast.losses import rmse, mae\n",
    "from utilsforecast.evaluation import evaluate\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import re\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import date_trunc, col, avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3999981-2287-48a9-b59b-b1799c320b47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Please replace the values `<CATALOG_NAME>` and `<SCHEMA_NAME>` with the specific values that match our use case and group. You can find the correct names by checking the **Unity Catalog** and look for the specific catalog and schema names:`uc_XXX`, `grpX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbf60b2d-d75d-40e4-894b-35074dfcfa76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- CREATE CATALOG IF NOT EXISTS <CATALOG_NAME>;\n",
    "SET CATALOG <CATALOG_NAME>;\n",
    "CREATE SCHEMA IF NOT EXISTS <SCHEMA_NAME>;\n",
    "USE SCHEMA <SCHEMA_NAME>;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "482cbccf-aa1c-4f9e-854d-cfa0f2cf55af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Load prepared time series table\n",
    "We load the prepared table generated by our Data Preparation scripts. Please replace the value `<PREPARED_TABLE_NAME>` with the prepared cashflow table name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3943b6d-49d6-4f4b-a1ec-58c01c6362fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = spark.read.table(\"<PREPARED_TABLE_NAME>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97e18790-667d-4fbd-9e49-1a1b72099a3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = data.withColumn(\"y\", data[\"y\"].cast(\"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a04d4c5-04df-4d06-840d-af15bf55c6b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Train forecasting model\n",
    "\n",
    "The **statsforecast** library is a high-performance Python package designed for univariate time series forecasting using statistical and econometric models. Itâ€™s developed by [Nixtla](https://nixtlaverse.nixtla.io/statsforecast/index.html) and is optimized for speed and scalability, making it suitable for both production environments and benchmarking.\n",
    "\n",
    "Furthermore, it is compatible with Spark and well integratable with MLFlow, which we use to log and track the training execution.\n",
    "\n",
    "**Models Included**:\n",
    "\n",
    "AutoARIMA, AutoETS, AutoCES, Theta, MSTL (Multiple Seasonalities)\n",
    "\n",
    "\n",
    "\n",
    "**Functionality**:\n",
    "- Probabilistic forecasting with confidence intervals\n",
    "- Support for exogenous variables and static covariates\n",
    "- Anomaly detection and cross-validation\n",
    "- Familiar .fit() and .predict() syntax like scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d29ad37-de5a-4155-9f7a-9ae6afb191c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For this exercise we set the `<LENGTH>` to the value `6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ebde9da-93f5-48da-b687-b274e7b6fcbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FORECAST_LENGTH = <LENGTH>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a5b99e9-539c-4b9c-bbbf-e132a57ec345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_date = data.select(\"ds\").distinct().orderBy(\"ds\")\n",
    "test_date = unique_date.tail(FORECAST_LENGTH)\n",
    "test_date = spark.createDataFrame(test_date)\n",
    "train_date = unique_date.join(test_date, \"ds\", \"leftanti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccb5700f-7c0c-4fa4-bb2d-2ee1099d9101",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data = data.join(train_date, \"ds\", \"inner\")\n",
    "test_data = data.join(test_date, \"ds\", \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc4d41a7-e262-47fe-9e06-cd9b49690682",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stats_forecast = StatsForecast(\n",
    "    models=[\n",
    "        ADIDA(),\n",
    "        AutoARIMA(),\n",
    "        CrostonOptimized(),\n",
    "        AutoETS(),\n",
    "        AutoCES(),\n",
    "        ARCH(),\n",
    "        AutoMFLES(\n",
    "            test_size=FORECAST_LENGTH, \n",
    "        ),\n",
    "        AutoTheta(),\n",
    "    ],\n",
    "    freq=\"MS\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6931a78-4de8-44e6-8256-49ca5337396f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec428cbc-cc69-4994-863f-c619639c5b02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Please be aware to replace the values `<DATE_COLUMN>`, `<VALUE_COLUMN>`, and `<ID_COLUMN>` with the actual column names from your dataset. \n",
    "\n",
    "> Hint: Those are the same columns that we created in the data preparation notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ad6e443-0229-4b5f-b002-e591ed574a33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To set the name of trained model we need log it via MLflow and replace `<MODEL_NAME>` with the value `statsforecast`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f833ceff-0453-4aed-a7d4-961784f1b563",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Remark: The execution of training will take approximately 2min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a9ae2aa-4210-4fa6-b287-2c1e3d561408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Please be aware to replace the values <DATE_COLUMN>, <VALUE_COLUMN>, and <ID_COLUMN> with the actual column names from your dataset. Hint: Those are the same columns that we created in the data preparation notebook.\n",
    "    DATE_COLUMN = '<DATE_COLUMN>'\n",
    "    ID_COLUMN= '<ID_COLUMN>'\n",
    "    VALUE_COLUMN = '<VALUE_COLUMN>'\n",
    "\n",
    "    prediction = stats_forecast.forecast(df=train_data, h=FORECAST_LENGTH, id_col=ID_COLUMN)\n",
    "    prediction = prediction.withColumn(DATE_COLUMN, date_trunc(\"MM\", col(DATE_COLUMN)))\n",
    "    model_list = prediction.drop(ID_COLUMN, DATE_COLUMN).columns\n",
    "    prediction_eval = prediction.join(test_data, [DATE_COLUMN, ID_COLUMN], \"inner\")\n",
    "    eval_df = evaluate(prediction_eval, metrics=[rmse, mae], models=model_list, id_col=ID_COLUMN, time_col=DATE_COLUMN, target_col=VALUE_COLUMN)\n",
    "    grouped_eval = eval_df.groupBy(\"metric\").agg(avg(col(\"ADIDA\")).alias(\"ADIDA\"), avg(col(\"AutoARIMA\")).alias(\"AutoARIMA\"), avg(col(\"CrostonOptimized\")).alias(\"CrostonOptimized\"), avg(col(\"AutoETS\")).alias(\"AutoETS\"), avg(col(\"CES\")).alias(\"CES\"), avg(col(\"ARCH(1)\")).alias(\"ARCH(1)\"), avg(col(\"AutoMFLES\")).alias(\"AutoMFLES\"), avg(col(\"AutoTheta\")).alias(\"AutoTheta\"))\n",
    "    grouped_eval_list = grouped_eval.toPandas().to_dict(orient=\"records\")\n",
    "    for element in grouped_eval_list:\n",
    "        metric_name = element.pop(\"metric\")\n",
    "        metrics = {f\"{metric_name}_{key}\": value for key, value in element.items()}\n",
    "        mlflow.log_metrics(metrics)\n",
    "    input_example = train_data.head(1)\n",
    "    input_example_df = pd.DataFrame(input_example, columns=train_data.columns)\n",
    "    prediction_df = pd.DataFrame(prediction.head(1), columns=prediction.columns)\n",
    "    signature = infer_signature(input_example_df, prediction_df)\n",
    "\n",
    "    # when model is logged, it will be also persisted in the unity catalog\n",
    "    model = mlflavors.statsforecast.log_model(\n",
    "        statsforecast_model=stats_forecast,\n",
    "        artifact_path=\"models\",\n",
    "        input_example=input_example_df,\n",
    "        signature=signature,\n",
    "        registered_model_name=\"<MODEL_NAME>\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd05d812-25f3-41a9-803a-612310807f52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When executed successfully, you should be able to find the trained model `statsforecast` in the Unity Catalog under your created SCHEMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "455e37e4-e772-4170-8d15-ef112669c903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow_client = MlflowClient()\n",
    "mlflow_client.set_registered_model_alias(\n",
    "    name=\"<MODEL_NAME>\",  # registered model name\n",
    "    alias=\"prod\",       # alias name\n",
    "    version=model.registered_model_version  # version number\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "322363c5-1cb4-4f35-9f07-abd8f9bdac15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Evaluating the logged performance in mlflow%md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b44e443-ac33-41e4-8289-2d56ea7f8ab0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Since we have logged the execution using MLflow, we can get more detailed analysis on the execution of the training itself:\n",
    "\n",
    "1. Click in the above cell with `mlflow.start_run(...)` on `See Performance` to get all executed statements listed.\n",
    "2. Click on one of the statements to get additional information such as *memory consumption*, *number of rows read*, *number of rows returned*, etc.\n",
    "3. Click on **`query profile`**, which will show:\n",
    "    - Execution plan (steps taken to run the query)\n",
    "    - Time spent on each operation\n",
    "    - CPU, memory, and I/O usage\n",
    "    - Bottlenecks or inefficient joins/scans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65996e16-03e7-4acf-80f5-cf68a75b0b11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The query profile is a very useful tool for:\n",
    "- Performance tuning: Identify slow steps and optimize them.\n",
    "- Cost control: Reduce compute time and resource usage.\n",
    "- Debugging: Understand why a query fails or returns unexpected results"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7791789125133167,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Cash_Liquidity_Training",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
