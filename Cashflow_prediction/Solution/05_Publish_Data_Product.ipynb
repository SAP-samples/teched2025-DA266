{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00ba7deb-1094-4a9a-84cf-b2f11363566a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## Publish a Data Product\n",
    "In this notebook we want to publish the cashflow prediction results to the data catalog of SAP Business Data Cloud. For that we need to build a custom data product by using the python library [sap-bdc-connect-sdk](https://pypi.org/project/sap-bdc-connect-sdk/). We will also utilize the [Delta Share protocol](https://delta.io/sharing/), which allows us to share the data product without the need of copying the result table. The result table remains persisted in SAP Databricks, and will be remotely accessible from the data catalog. \n",
    "\n",
    "The following steps need to be applied in this exercise:\n",
    "\n",
    "1. Install and load packages\n",
    "2. Create a client for sap-bdc-connect-sdk\n",
    "3. Create Delta Share\n",
    "4. Add Recipient to Share\n",
    "5. Create Open Resource Discovery (ORD) object\n",
    "6. Create Core Schema Notation (CSN) object\n",
    "7. Publish data product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df9c8c26-9466-4198-b7be-324841a8727a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "> **Pre-requisite: SECRET SCOPE**\n",
    ">\n",
    "> This step has already been done by the administrator to facilitate the sharing process. However, if you need to do > it on you own you can follow the steps described here to create a secret scope:\n",
    ">\n",
    "> To create a secret scope you can either use the following URL https://<databricks-instance>#secrets/createScope. \n",
    "> Replace <databricks-instance> with the workspace URL of your Databricks deployment.\n",
    ">\n",
    "> Alternatively, you can run the following command in the terminal by clicking on the terminal icon on the lower  right corner: `databricks secrets create-scope sap-bdc-connect-sdk`. \n",
    ">\n",
    ">The secret scope only has to be created once and can be made accessible to all workspace users by either toggling  `manage principal` to `all workspace users` or via the terminal using the following command `databricks secrets put-acl sap-bdc-connect-sdk users READ`. To check whether the assignment worked, you can then use the command `databricks secrets list-acls sap-bdc-connect-sdk`.\n",
    ">\n",
    "> A full explanation can be found here https://docs.databricks.com/aws/en/security/secrets/example-secret-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da3bd2cb-fb2f-4acd-a05c-faca59ee518b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Install and load Packages\n",
    "To be able to share the enhanced data products back to SAP Business Data Cloud, we need the `SAP SDK` (https://pypi.org/project/sap-bdc-connect-sdk/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b41eb27c-0f38-4869-9c77-52d1dcd3fc60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install sap-bdc-connect-sdk\n",
    "%pip install --upgrade pydantic\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7ed064e-1765-4b3a-a618-3c54020c4599",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Check the sdk details and version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02fe2b63-69d4-46ff-b3dc-6d1c6520bf11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip show sap-bdc-connect-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83fa375d-1243-4d2d-a462-9b116f6eb2e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Create a client for sap-bdc-connect-sdk\n",
    "The `DatabricksClient` receives dbutils as a parameter, which is a Databricks utility that can be used inside the Databricks notebooks.\n",
    "\n",
    "The `BdcConnectClient` receives the DatabricksClient as a parameter to get information from the Databricks environment (e.g. secrets, api_token, workspace_url_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccc8a15a-ea70-44ec-8785-588203dbe280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from bdc_connect_sdk.auth import BdcConnectClient\n",
    "from bdc_connect_sdk.auth import DatabricksClient\n",
    "from bdc_connect_sdk.utils import csn_generator\n",
    "import json\n",
    "\n",
    "databricks_client = DatabricksClient(dbutils)\n",
    "bdc_connect_client = BdcConnectClient(databricks_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aaff699-6404-4d16-aa60-f867af2ab311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Create Delta Share\n",
    "A share is a mechanism for distributing and accessing data across different systems. Creating or updating a share involves including specific attributes, such as @openResourceDiscoveryV1, in the request body, aligning with the Open Resource Discovery protocol. This procedure ensures that the share is properly structured and described according to specified standards, facilitating effective data sharing and management. This is done in step 5.\n",
    "\n",
    "Please replace the values `<CATALOG_NAME>` and `<SCHEMA_NAME>` with the specific values that match our use case and group. You can find the correct names by checking the **Unity Catalog** and look for the specific catalog and schema names: `uc_XXX`, `grpX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4442587-e6c9-49fc-b44e-ef9eacc1e6f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- CREATE CATALOG IF NOT EXISTS <CATALOG_NAME>;\n",
    "SET CATALOG uc_cash_liquidity_forecast;\n",
    "CREATE SCHEMA IF NOT EXISTS grp01;\n",
    "USE SCHEMA grp01;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce21d115-9424-4de6-9c86-c354452a7556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now let's create the Delta Share and include the two results tables created in the schema into the Delta Share. \n",
    "\n",
    "Please replace variable `<SHARE_NAME>` with the value `grpX_share_cash_liquidity`, and the variable `<PREDICTION_RESULT_TABLE_NAME>` with the corresponding table names of the Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "510ea854-a9ab-499d-a1e5-7ea8e5decebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SHARE IF NOT EXISTS grp01_share_cash_liquidity;\n",
    "ALTER SHARE grp01_share_cash_liquidity ADD TABLE cashflow_prediction WITH HISTORY;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "768e6ff3-be53-45f7-9011-1912daa22c0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Add Recipient to Share\n",
    "\n",
    "To be able to share the data product to BDC we need to select `sap-business-data-cloud` as the recipient for the share we've just created. \n",
    "\n",
    "The recipient can be added using the following query. Please fill in the variable `<RECIPIENT_NAME>` with the value `sap-business-data-cloud`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f32d750f-2f3f-46f2-9962-cdfb4ebc825c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "GRANT SELECT ON SHARE grp01_share_cash_liquidity TO RECIPIENT `sap-business-data-cloud`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14bf5de4-e18b-4173-8fb2-24866a2836c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "Remark: Alternatively, this can be done by heading over to the **Unity Catalog** > **Delta Sharing** > **Shared by me** > *Select Share* > **Recipient** > **Add Recipients** > *Select sap-business-data-cloud*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d9bb856-c490-4a80-97c8-a00f53fce45c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Create Open Resource Discovery (ORD) object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ffada4-40b9-436c-b930-7e5651fa7284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "Creating or updating a share involves including specific attributes, such as @openResourceDiscoveryV1, in the request body, aligning with the [Open Resource Discovery protocol](https://open-resource-discovery.github.io/specification/). This procedure ensures that the share is properly structured and described according to specified standards, facilitating effective data sharing and management. This is done in step 5.\n",
    "\n",
    "In the following code you'll need to set the parameters for the share:\n",
    "- `<DATA_PRODUCT_NAME>` : \n",
    "    - e.g. \"grpxx Cashflow Prediction\"\n",
    "- `<SHORT_DESCRIPTION>` : \n",
    "    - e.g. \"grpxx Data Produt for Cashflow Prediction\"\n",
    "- `<LONG_DESCRIPTION>`: \n",
    "    - e.g. \"This data product contains the data used for the cashflow prediction model. A hyperparameter optimization is performed on the cleased data with the help of the Bayesian Search optimization. For the clustering we use the Affinity Propagation algorithm. After the hyperparameter optimization is performed, the model with the highest silhouette score is applied as the best model to the prepared clustering dataset. The resulting clustering labels are stored and merged together with a T-SNE based representation of the input dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2e20976-2e8b-4f13-84be-efc5b760c77a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from bdc_connect_sdk.auth import BdcConnectClient\n",
    "from bdc_connect_sdk.auth import DatabricksClient\n",
    "\n",
    "bdc_connect_client = BdcConnectClient(DatabricksClient(dbutils, \"sap-business-data-cloud\"))\n",
    "\n",
    "share_name = \"grp01_share_cash_liquidity\"\n",
    "\n",
    "open_resource_discovery_information = {\n",
    "    \"@openResourceDiscoveryV1\": {\n",
    "        \"title\": \"grp01 Cashflow Predictions Data Product\",\n",
    "        \"shortDescription\": \"Data asset for cashflow predictions\",\n",
    "        \"description\": \"This data product contains the data used for the cashflow prediction model. A hyperparameter optimization is performed on the cleased data with the help of the Bayesian Search optimization. For the clustering we use the Affinity Propagation algorithm. After the hyperparameter optimization is performed, the model with the highest silhouette score is applied as the best model to the prepared clustering dataset. The resulting clustering labels are stored and merged together with a T-SNE based representation of the input dataset.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = bdc_connect_client.create_or_update_share(\n",
    "    share_name,\n",
    "    open_resource_discovery_information\n",
    ")\n",
    "print(f\"[REQUEST] Create or update share request was executed and returned {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "917bd1c0-f499-46bb-88da-5f34fa2ec02e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. Create Core Schema Notation (CSN) object\n",
    "\n",
    "The Core Schema Notation (CSN serves as a standardized format for configuring and describing shares within a network. To create or update the CSN for a share, it's advised to prepare the CSN content in a separate file and include this content in the request body. This approach ensures accuracy and compliance with the CSN interoperability specifications, facilitating consistent and effective share configuration across systems.\n",
    "\n",
    "In the following code you'll need to set the parameters `<RECIPIENT_NAME>` and `<SHARE_NAME>` for the share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cea417d-e669-419f-85c6-a44dcc272656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from bdc_connect_sdk.auth import BdcConnectClient\n",
    "from bdc_connect_sdk.auth import DatabricksClient\n",
    "from bdc_connect_sdk.utils import csn_generator\n",
    "\n",
    "bdc_connect_client = BdcConnectClient(DatabricksClient(dbutils, \"sap-business-data-cloud\"))\n",
    "\n",
    "share_name = \"grp01_share_cash_liquidity\"\n",
    "\n",
    "csn_schema = csn_generator.generate_csn_template(share_name)\n",
    "\n",
    "response = bdc_connect_client.create_or_update_share_csn(\n",
    "    share_name,\n",
    "    csn_schema\n",
    ")\n",
    "print(f\"[REQUEST] Create or update CSN request was executed and returned {response if response else 'OK'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c90796fd-53d6-4495-a662-f39ca3b0be95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 7. Publish a Data Product\n",
    "A Data Product is an abstraction that represents a type of data or data set within a system, facilitating easier management and sharing across different platforms. It bundles resources or API endpoints to enable efficient data access and utilization by integrated systems. Publishing a Data Product allows these systems to access and consume the data, ensuring seamless communication and resource sharing.\n",
    "\n",
    "In the following code you'll need to set the parameters `<RECIPIENT_NAME>` and `<SHARE_NAME>` for the share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "045aff67-f2d3-4f9c-9ca5-bd9ef83884b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from bdc_connect_sdk.auth import BdcConnectClient\n",
    "from bdc_connect_sdk.auth import DatabricksClient\n",
    "\n",
    "bdc_connect_client = BdcConnectClient(DatabricksClient(dbutils, \"sap-business-data-cloud\"))\n",
    "\n",
    "share_name = \"grp01_share_cash_liquidity\"\n",
    "\n",
    "response = bdc_connect_client.publish_data_product(\n",
    "    share_name\n",
    ")\n",
    "print(f\"[REQUEST] Publish Data Product request was executed and returned {response if response else 'OK'}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5370185177402458,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "05_Publish_Data_Product",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
