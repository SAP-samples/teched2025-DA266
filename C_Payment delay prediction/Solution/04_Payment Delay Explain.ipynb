{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "263402ab-2336-474c-913c-6949d60e5e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Payment Delay Explain\n",
    "In this notebook we will explain the payment delays prediction and key drivers by using natural language, so that a business user can easily comprehend the results. For that, we will use SAP AI Foundation services for Large Language Model (LLM) and intepret the prediction results and the corresponding SHapley Additive exPlanations (SHAP) values from the previous exercise. \n",
    "\n",
    "We demonstrate this through the example of [SAP AI Core Orchestration Service](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/orchestration-8d022355037643cebf775cd3bf662cc5?locale=en-US), which provides harmonized access to a wide range of frontier AI / LLM models. The orchestration service will be exposed as an MLflow model, for fully integrated downstream processing in SAP Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a739e220-446b-4ca2-b968-2ab414624101",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Install necessary packages\n",
    "In the next few cells, we will install and import the required packages. Please make sure, that we use the right versions of the libraries. While SAP AI Core capabilities are exposed via a REST API (see the [documentation on the SAP Business Accelerator Hub](https://api.sap.com/package/SAPAICore/rest)), this guide leverages the SAP Cloud SDK for AI (Python) to simplify consumption within Databricks notebooks. This SDK [sap-ai-sdk-gen](https://pypi.org/project/sap-ai-sdk-gen/) is free for download from PyPI and is documented on the [SAP Help Portal](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66b87703-9de9-478a-b310-e6ab0363cc95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install \"sap-ai-sdk-gen[all]\"\n",
    "%pip install \"mlflow[databricks]==3.1.3\"\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc518e0f-095a-4f80-b5aa-ec52946fac3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "629c7fce-a5f2-493b-b91a-8f3f3c05c130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import datetime, time\n",
    "from typing import List, Optional, Iterable, Union, Dict, Any\n",
    "import httpx\n",
    "import mlflow\n",
    "import gen_ai_hub as gen_ai_hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3fedef6-da03-4ad2-ab5b-e92ed2de68bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Configure SECRET scope for secure access of SAP Cloud SDK for AI\n",
    "First, create a secret scope named aicore_service_params as environment variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddaca63b-d9d1-4504-9d60-f17ecd8f05e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SECRET_SCOPE = \"aicore_service_params\"\n",
    "# single env var provided to model\n",
    "os.environ[\"SECRET_SCOPE\"] = SECRET_SCOPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "950cc051-3fc7-48cc-9748-c42c321d14cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To securely store and access SAP AI Core credentials from within SAP Databricks, create a Databricks secret(refer to [Databricks documentation on creating secret scopes](https://docs.databricks.com/aws/en/security/secrets)). \n",
    "\n",
    "Then, store the following access parameters as case-sensitive key-value pairs within this scope, as they are [defined in the documentation of the generative AI SDK](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/README_sphynx.html#environment-variables):\n",
    "\n",
    "- AICORE_BASE_URL\n",
    "- AICORE_AUTH_URL\n",
    "- AICORE_CLIENT_ID\n",
    "- AICORE_CLIENT_SECRET\n",
    "- AICORE_RESOURCE_GROUP\n",
    "\n",
    "Setting these credentials as environment variables allows the SAP Cloud SDK for AI (Python) to seamlessly authenticate and interact with the SAP AI Core orchestration service within the Databricks runtime. The SAP Cloud SDK for AI (Python) automatically manages the configuration and deployment of orchestration service endpoints and the desired Large Language Models (LLMs) upon initial use.\n",
    "\n",
    "> [!IMPORTANT]\n",
    "> The SECRET scope should have been already configured by your system administrator. For this exercise we will just consume the corresponding AI SDK service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6aeb0aa6-8b2c-438c-a53c-b693f765f695",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Data\n",
    "Replace \\<DELAY_PREDICTION_SHAP_TABLE\\> with the name of the delay prediction result table from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abb64207-f235-4485-a1e4-fb99ca1fd093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap_table_df = spark.read.table(\"uc_delayed_payment.grp1.delay_prediction_dataset_shap_martin\")\n",
    "# display(shap_table_df.limit(10))\n",
    "print(f\"rows: {shap_table_df.count()}, columns: {len(shap_table_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b63834be-e0f6-4844-a64b-09634894abcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Filter payment delays prediction data for explanation \n",
    "\n",
    "We will use only a subset of the prediction dataset to apply the LLM explanation. For that we create a data smaple of top 5 delays. Replace the \\<LIMIT\\> with the value 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f354083c-1c4c-40e8-9bcb-143a0c131c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_data_example_pdf = shap_table_df.orderBy(\"delay_prediction\", ascending=False).limit(5).toPandas()\n",
    "display(input_data_example_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d389056-10ce-4a4a-8e10-0aa4ec47f4b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. load Orchestration Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fa3c321-2cb7-45d9-be83-7f02bf3f4093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./util\")\n",
    "#from util.wrapped_orchestration_service import OrchestrationConfig, OrchestrationService, OrchestrationError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1680f275-30e1-4379-b243-1880974e5e32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "788b7144-621c-4ca3-9f46-ca1e92036e83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.exceptions  import OrchestrationError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba57bb24-c26a-454d-88db-4334d8b7fa5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. define delay prediction explanation model (with limited MLFlow logging initially)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ecb6e48-22d0-423b-ad35-43004244f65d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Work in Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be26efac-9008-4b2b-910d-8c5a5567d198",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "key_columns = [\"CompanyCode\", \"AccountingDocument\", \"FiscalYear\", \"AccountingDocumentItem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b54140d3-2305-432e-8942-f7494b9e934a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from gen_ai_hub.orchestration.models.message import UserMessage\n",
    "import gen_ai_hub\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.message import UserMessage\n",
    "from typing import Dict, Any\n",
    "from mlflow.tracing import set_span_chat_messages\n",
    "\n",
    "\n",
    "class ExplanationModel(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature_descrptions = None\n",
    "        self.key_columns = None\n",
    "        self.llm_model = \"gpt-4o-mini\"\n",
    "        self.max_tokens = 1000\n",
    "\n",
    "    def load_key_column_names(self, key_columns):\n",
    "        self.key_columns = key_columns\n",
    "\n",
    "\n",
    "    def build_prompt(self, row: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        We construct the prompt from \"shap_array\" as a dynamic set of parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        # identify the 5 most important features\n",
    "        shap_value_array = sorted( row[\"shap_array\"], key = lambda x: (abs(x[\"shap_value\"])), reverse=True)\n",
    "\n",
    "        included_feature_number = 5\n",
    "        \n",
    "        feature_descriptions_md = \"\"\n",
    "        feature_values_md = \"\"\n",
    "        shap_values_md = \"\"\n",
    "\n",
    "        for i in range(included_feature_number):\n",
    "            shap_array_item = shap_value_array[i]\n",
    "            feature_descriptions_md += f\"- '{shap_array_item['column_name']}': {shap_array_item['column_description']}\\n\"\n",
    "            feature_values_md +=  f\"- Value of '{shap_array_item['column_name']}': {shap_array_item['column_value']}\\n\"\n",
    "            shap_values_md += f\"- SHAP value for '{shap_array_item['column_name']}': {shap_array_item['shap_value']} days\\n\"\n",
    "\n",
    "\n",
    "        prompt = \"You are a data scientist who explains predictions of a business artificial intelligence model.\\n\"\n",
    "        prompt += \"The model predicts the expected delay for a payment.\\n\"\n",
    "\n",
    "        prompt += \"\\nThe following payment attributes are relevant for the prediction:\\n\"\n",
    "        prompt += feature_descriptions_md\n",
    "\n",
    "        prompt += \"\\nValues of these payment attributes:\\n\"\n",
    "        prompt += feature_values_md\n",
    "\n",
    "        prompt += \"\\nSHAP values for the attribute:\\n\"\n",
    "        prompt += shap_values_md\n",
    "\n",
    "        #TODO: add confidence etc\n",
    "\n",
    "        prompt += f\"\\nThe SHAP value for a feature decribes to what amount the predicted delay of {row['delay_prediction']} days deviates from the average value. A negative SHAP value for a feature means that the feature value reduces the prediction below average, while a positive value means that the feature value increases the prediction above average.\\n\"\n",
    "        prompt += \"Your task is to explain this specific prediction in a concise manner to a business person who is not a data scientist and who wants to understand which features are relevant for the prediction.\"\n",
    "        prompt += \" Do not mention the SHAP values in your explanation. You can use the feature values.\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "\n",
    "\n",
    "    def init_orchestration_service(self) -> OrchestrationService:\n",
    "        \"\"\" \n",
    "        Initialize the configured orchestration service.\n",
    "        \"\"\"\n",
    "\n",
    "        # get secet scope\n",
    "        secret_scope = os.environ['SECRET_SCOPE']\n",
    "\n",
    "        # set secret values as environment variables\n",
    "        for key in [\"AICORE_CLIENT_ID\", \"AICORE_CLIENT_SECRET\", \"AICORE_AUTH_URL\", \"AICORE_BASE_URL\", \"AICORE_RESOURCE_GROUP\"]:\n",
    "            os.environ[key] = dbutils.secrets.get(scope = secret_scope, key=key)\n",
    "\n",
    "        user_message_content = \"{{?prompt}}\"\n",
    "\n",
    "        orchestration_config = OrchestrationConfig(\n",
    "            template=Template(messages=[UserMessage(user_message_content)]),\n",
    "            llm=LLM(name=self.llm_model, parameters={\"max_tokens\": self.max_tokens})\n",
    "        )\n",
    "\n",
    "        return OrchestrationService(config = orchestration_config)\n",
    "\n",
    "\n",
    "    def predict(self, model_input, params=None):\n",
    "        \"\"\" \n",
    "        Process the model inuput:\n",
    "        Expected input: Pandas DataFrame with \n",
    "        - key columns, with column names as listed in the list 'key_columns'\n",
    "        - columns 'shap_array', where each entry has the key 'column_name', 'column_description', 'column_value', 'shap_value' (all double)\n",
    "        - column 'delay_prediction'\n",
    "        Generated output: Pandas DataFrame with \n",
    "        - key columns,\n",
    "        - column 'delay_prediction' (double), and \n",
    "        - colums 'deplay_explanation' (string)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        orchestration_service = self.init_orchestration_service() \n",
    "\n",
    "        model_output = []\n",
    "        rows = json.loads(model_input.to_json(orient='records'))\n",
    "\n",
    "        for row in rows:\n",
    "\n",
    "            row_result = {}\n",
    "            for key in self.key_columns:\n",
    "                row_result[key] = row[key]\n",
    "\n",
    "            row_result[\"delay_prediction\"] = row[\"delay_prediction\"]\n",
    "\n",
    "            template_values = []\n",
    "            prompt = self.build_prompt(row)\n",
    "            template_values.append(TemplateValue(name=\"prompt\", value=prompt))\n",
    "\n",
    "            with mlflow.start_span(name=\"shap_explanation\", span_type=\"LLM\") as span:\n",
    "\n",
    "                span.set_inputs(row)\n",
    "                try:\n",
    "                    orchestrationResponse = orchestration_service.run(template_values=template_values)\n",
    "                    orchestration_result = orchestrationResponse.orchestration_result\n",
    "                    \n",
    "                    choice = orchestration_result.choices[0]\n",
    "                    completion = choice.message.content\n",
    "                    row_result[\"deplay_explanation\"] = completion\n",
    "                    messages = [{\"role\": message.role.value, \"content\": message.content} for message in orchestrationResponse.module_results.templating]\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": completion})\n",
    "                    set_span_chat_messages(span, messages)\n",
    "                    span.set_attributes({\"model_name\": self.llm_model, \"max_tokens\": self.max_tokens})\n",
    "                    span.set_outputs({\"prompt\": prompt, \"delay_explanation\": completion})\n",
    "\n",
    "                except OrchestrationError as error:\n",
    "                    model_output.append(error.message)\n",
    "                    span.set_outputs({\"ERROR\": error.message})\n",
    "\n",
    "\n",
    "                model_output.append(row_result)\n",
    "        \n",
    "        \n",
    "        pd_model_output = pd.DataFrame.from_records(model_output)\n",
    "        return pd_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1bbfb35-8efb-4d23-b217-19e1d6bb1cb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "096c3768-a4b2-40e1-a767-7444f8f57cf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "explanation_model = ExplanationModel()\n",
    "\n",
    "explanation_model.load_key_column_names(key_columns)\n",
    "# explanation_model.load_feature_decriptions(feature_descrptions)\n",
    "\n",
    "\n",
    "# test prompt generation\n",
    "output_example_pdf = explanation_model.predict(input_data_example_pdf)\n",
    "\n",
    "display(output_example_pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97fe848b-9de7-48fe-b81d-17cbfbfc7124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "NOTE:\n",
    "- orchestration **service calls are traced in this experiment** https://dbc-6d11e582-1008.cloud.databricks.com/ml/experiments/139cee9231254a69a1821d60f7bc3504?o=331377520300711&searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D&compareRunsMode=TRACES "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5705242598846492,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Payment Delay Explain",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
