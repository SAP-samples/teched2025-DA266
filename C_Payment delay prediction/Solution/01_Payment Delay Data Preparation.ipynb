{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bb34047-459d-4f9f-881d-90c630f5ac9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Preparation Notebook\n",
    "\n",
    "This notebook will cover the set up and cleaning of the data. We will prepare the data by handling missing values, removing duplicates and updating data types. Additionally, we will normalize the data, encode categorical variables and create new features. This is followed by a visualization of the distribution to identify any patterns or anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b574e3a-bc2c-440e-b7b5-49b8b96598f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Install necessary packages\n",
    "\n",
    "In the next few cells, we will install and import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69875e7a-73c2-46ee-a711-70c76799a340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature-engineering\n",
    "%pip install ydata-profiling\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10894065-6b52-4ffb-85c2-514b800ed60c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36c6d60c-aeea-43ab-bb2d-d9f32ea6f463",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date, col, date_trunc, sum, explode, sequence, min, max, lit, expr, datediff, row_number, when\n",
    "from pyspark.sql.window import Window\n",
    "from ydata_profiling import ProfileReport\n",
    "import pandas as pd\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "867ef342-4de4-4ce5-b96d-27e216d59ce5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set necessary parameters\n",
    "\n",
    "Please replace the values `<CATALOG_NAME>` and `<SCHEMA_NAME>` with the specific values that match our use case and group. You can find the correct names by checking the **Unity Catalog** and look for the specific catalog and schema names:`uc_XXX`, `grpX`. Additionally, please replace the value `<TIME_SERIES_TABLE_NAME>` with the according name. \n",
    "\n",
    "Please note: \n",
    "We adapted the code here to match our use case. Therefore, some of the lines are commented out and not needed. However, they can be useful for future applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97d7ef95-e2b9-4333-b518-55b65a34a0d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS uc_delayed_payment;\n",
    "SET CATALOG uc_delayed_payment;\n",
    "CREATE SCHEMA IF NOT EXISTS grp1;\n",
    "USE SCHEMA grp1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb51d4f4-768a-49cb-8573-2715d3f98f86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Replace the values `<DELTA_SHARE>` with the according `cashflow` delta share name. You'll find the correct name by checking the **Unity Catalog**. \n",
    "\n",
    "Hint: You'll need to refer to the correct table within the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d254fa6c-b028-4747-96c5-64331d4e3078",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = spark.read.table(\"bdc_share_journal_entry.entryviewjournalentry.operationalacctgdocitem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5817296f-292c-4d02-bd33-974622ba10ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Preparation\n",
    "Use the following code to drop unneccessary columns. Add the following columns to the list of columns that need to be dropped (`<COLUMNS_TO_DROP>`): \n",
    "- CashDiscount2DueDate\n",
    "- CashDiscount1DueDate\n",
    "- DocumentDate\n",
    "- PostingDate\n",
    "- TaxDeterminationDate\n",
    "- AcctgDocItmCstmsClearanceDate\n",
    "- DueCalculationBaseDate\n",
    "- AssetValueDate\n",
    "- ValueDate\n",
    "- ClearingCreationDate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26caa8e6-11db-42eb-881e-b7b3c288c494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "selected_data = data.drop(\"CashDiscount2DueDate\", \"CashDiscount1DueDate\", \"DocumentDate\", \"PostingDate\", \"TaxDeterminationDate\", \"AcctgDocItmCstmsClearanceDate\", \"DueCalculationBaseDate\", \"AssetValueDate\", \"ValueDate\", \"ClearingCreationDate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66d7d3d1-0cd0-4db3-97a2-f6583bfe0331",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now adjust the following code to replace empty strings with `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68fb9bbe-9816-4055-90e5-2fd76a387c66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactional_data = selected_data.replace('', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3958458c-362e-4ec0-af6a-1bb3efa95549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c492a70-63c9-49e8-a2ef-ce6f32323079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the following cell, we will drop unnecessary columns from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ddcc7ac-884b-4565-850a-4098d77f279d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def drop_fully_null_columns(df, but_keep_these=[]):\n",
    "    \"\"\"Drops DataFrame columns that are fully null\n",
    "    (i.e. the maximum value is null)\n",
    "\n",
    "    Arguments:\n",
    "        df {spark DataFrame} -- spark dataframe\n",
    "        but_keep_these {list} -- list of columns to keep without checking for nulls\n",
    "\n",
    "    Returns:\n",
    "        spark DataFrame -- dataframe with fully null columns removed\n",
    "    \"\"\"\n",
    "\n",
    "    # skip checking some columns\n",
    "    cols_to_check = [col for col in df.columns if col not in but_keep_these]\n",
    "    if len(cols_to_check) > 0:\n",
    "        # drop columns for which the max is None\n",
    "        rows_with_data = df.select(*cols_to_check).groupby().agg(*[max(c).alias(c) for c in cols_to_check]).take(1)[0]\n",
    "        cols_to_drop = [c for c, const in rows_with_data.asDict().items() if const == None]\n",
    "        cleaned_df = df.drop(*cols_to_drop)\n",
    "\n",
    "        return cleaned_df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41aa1687-674b-4740-8251-5ad3aa09567d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Set the primary keys by adding the following columns to the list of primary keys `<PRIMARY_KEYS>`. The following columns should be set as primary keys:\n",
    "- CompanyCode\n",
    "- AccountingDocument\n",
    "- FiscalYear\n",
    "- AccountingDocumentItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37ebc351-cb70-4c51-8015-1e540a4cbc4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "primary_key = [\"CompanyCode\", \"AccountingDocument\", \"FiscalYear\", \"AccountingDocumentItem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "205001ae-321c-41a4-a1df-68929b46c11c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactional_data = transactional_data.where(col(\"Customer\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3760caa6-8b3d-474f-b5ad-1e73b5a879eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactional_data = drop_fully_null_columns(transactional_data)\n",
    "converted_data_types = {column: col(column).cast('integer').alias(column) for column, column_dtype in transactional_data.dtypes if column_dtype == 'boolean'}\n",
    "if converted_data_types:\n",
    "    transactional_data = transactional_data.withColumns(converted_data_types)\n",
    "replace_string_values = {column: f\"No{column}\" for column, col_dtypes in transactional_data.dtypes if col_dtypes == \"string\" and column not in primary_key}\n",
    "prepared_transactional_data = transactional_data.fillna(replace_string_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a37846f-4de5-4ccb-8f3a-6e61045e1e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Filter Data \n",
    "We only need the data where we have a value for the column `Customer`. Please adjust the following code to make sure data with the value `NoCustomer`is filtered out by replacing the value `<SET_FILTER>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1b767f-9256-4155-8dc7-0a39083a42b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prepared_transactional_data = prepared_transactional_data.where(col(\"Customer\") != \"NoCustomer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c86ae40-9e00-486f-ba2b-3a1dcd7b7ebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Delay Prediction\n",
    "To create a delay prediction data set we need to select the columns that have an actual delay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e02af51c-de40-409e-9451-b25e67a16bcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the delay in days between ClearingDate and NetDueDate\n",
    "delay_prediction_dataset = prepared_transactional_data.\\\n",
    "    withColumn(\"delay\", datediff(\"ClearingDate\", \"NetDueDate\")).\\\n",
    "    withColumn(\"delay\", when(col(\"delay\") < 0, 0).otherwise(col(\"delay\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e85b29a-2f53-4551-b57a-465078ecb457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For the column `delay` we need the values to be bigger or equal to `0`. Adjust the following code to match these requirements by changing the value of `<SET_FILTER>`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "930afe3b-c321-4deb-8ca4-460512a518e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "delay_prediction_dataset = delay_prediction_dataset.where(col(\"delay\") >= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82c308b3-1f18-4fe7-a9d5-754e096f28fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create and Save Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "995808b0-628e-4f8a-a623-b3d7f4031fbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "fe_client = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2e9399e-6f37-4471-8758-c212fed173f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe_client.create_table(\n",
    "    name=\"prepared_accounting_document\",\n",
    "    primary_keys=primary_key,\n",
    "    schema=delay_prediction_dataset.schema,\n",
    "    description=\"Prepared Accounting document item data product for payment delay forecasting\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47f643fe-b721-4c7e-922e-f58fbadc3a4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next, replace `<TABLE_NAME>` by the name of the table that we created for the delay prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "554c9448-7049-4cd0-848f-b29c263dc227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe_client.write_table(\n",
    "    name=\"prepared_accounting_document\",\n",
    "    df=delay_prediction_dataset,\n",
    "    mode=\"merge\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5931443015856522,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Payment Delay Data Preparation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
