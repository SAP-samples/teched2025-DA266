{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ce2dad4-e806-4270-a0c5-79dfeec2152b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Payment Delay Training \n",
    "\n",
    "This notebook is designed to train a model for predicting payment delays. We will load and prepare the preprocessed data, handle missing values and encode categorical variables. The model training then consists of several steps to fit the models and select the best parameters for our final model. We will evaluate the models using various metrics to determine the best model.\n",
    "\n",
    "This are the steps for this exercise: \n",
    "\n",
    "1. Install and import packages\n",
    "2. Load prepared data\n",
    "3. Create training andn test data\n",
    "4. Train a forecast model\n",
    "5. Apply hyperparameter optimization\n",
    "6. Register and persist trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d658da2-cbaa-4b2e-ae82-ffd5698193d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Install and Import Packages\n",
    "All necessary packages for this notebook are going to be outlined in the following notebook cell. In order to make sure that the results are reproducible, the following packages are going to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2899d8a3-c072-4e73-bf7f-bcf4b42dfef0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install xgboost\n",
    "%pip install optuna\n",
    "%pip install optuna-dashboard\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e0d7806-b131-4ab9-9947-c308fa0a15c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.client import MlflowClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import optuna\n",
    "import optuna.visualization as ov\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a40e7de8-c109-47ff-b1ed-109f326d9348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# &#x270D;\n",
    "In order to isolate the created data assets, we create a catalog within Databricks and a respective schema within the catalog. Please replace the values `<CATALOG_NAME>` and `<SCHEMA_NAME>` with the specific values that match our use case and group. You can find the correct names by checking the **Unity Catalog** and look for the specific catalog and schema names:`uc_XXX`, `grpX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bb6f6bc-9fe7-4617-b540-21197af3c93f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- CREATE CATALOG IF NOT EXISTS <CATALOG_NAME>;\n",
    "SET CATALOG <CATALOG_NAME>;\n",
    "-- CREATE SCHEMA IF NOT EXISTS <SCHEMA_NAME>;\n",
    "USE SCHEMA <SCHEMA_NAME>;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "979690d8-79ef-4edb-9ced-6efb6fe25fe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Load prepared data\n",
    "# &#x270D;\n",
    "Replace the value `<PREPARED_TABLE_NAME>` with the name of the table that we created with the data preparation notebook. Additionally, set the value `<SEED_PARAMETER>` with a random number, which is used to ramdomly filter on a subset of the data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06d61399-64a1-4194-b559-bea129df8045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = (spark.read.table(\"<PREPARED_TABLE_NAME>\").\n",
    "    where(col(\"delay\").isNotNull()).\n",
    "    drop(\"ClearingDate\", \"NetDueDate\").\n",
    "    sample(0.25, seed=<SEED_PARAMETER>))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "366e208b-1531-4194-8232-4f06c9c0eacc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.Create training and test data\n",
    "In the following step we will create a train-test split and focus on the column `delay`. We will also check the data types and adjust accordingly. Once the data is ready, we can continue with the actual model training\n",
    "\n",
    "# &#x270D;\n",
    "Please adjust the code by setting the values for `<SPLIT>`. We aim for an 80% / 20% train-test split. Also, set a random number for the value `<SEED_PARAMETER>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa7b984-2253-4c78-9aad-ad0825370ac1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31333176-638a-44c0-bed2-6a0a91a1a74f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = data.drop(\"CompanyCode\", \"AccountingDocument\", \"FiscalYear\", \"AccountingDocumentItem\").randomSplit([<SPLIT>], seed=<SEED_PARAMETER>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d01b488d-e2e9-490e-ab80-7c338997062b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The next cell converts the Spark DataFrames `train_df` and `test_df` into Pandas DataFrames.\n",
    "It separates the target variable \"delay\" from the features for both training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1ccf659-b879-4063-89fc-def603c41ddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_target = train_df.select(\"delay\").toPandas()\n",
    "train_data = train_df.drop(\"delay\").toPandas()\n",
    "test_target = test_df.select(\"delay\").toPandas()\n",
    "test_data = test_df.drop(\"delay\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1152820a-71c8-4e8a-9bf5-f215c5a691a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# &#x270D;\n",
    "In the following function `infer_column_dtype` we want to return the strings `numeric`, `datetime` or `boolean` depending on the data type of the column. Please adjust the return statements accordingly by replacing `<DTYPE>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "916d179b-5c46-42db-ab36-1eecbbe46a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def infer_column_dtype(series):\n",
    "    # Try to convert to numeric\n",
    "    try:\n",
    "        pd.to_numeric(series.dropna())\n",
    "        return '<DTYPE>'\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Try to convert to datetime\n",
    "    try:\n",
    "        pd.to_datetime(series.dropna(), errors='raise', infer_datetime_format=True)\n",
    "        return '<DTYPE>'\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # If all unique values are 'True' or 'False' like\n",
    "    lower_vals = set(str(v).strip().lower() for v in series.dropna().unique())\n",
    "    if lower_vals <= {'true', 'false', '1', '0'}:\n",
    "        return '<DTYPE>'\n",
    "    \n",
    "    return 'string'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdf2ba4d-5b9a-4d0a-9bdd-63fc2fc0aa71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# apply to train data\n",
    "for col in train_data.columns:\n",
    "    inferred = infer_column_dtype(train_data[col])\n",
    "    if inferred == 'numeric':\n",
    "        train_data[col] = pd.to_numeric(train_data[col], errors='coerce')\n",
    "    elif inferred == 'datetime':\n",
    "        train_data[col] = pd.to_datetime(train_data[col], errors='coerce')\n",
    "    elif inferred == 'boolean':\n",
    "        train_data[col] = train_data[col].astype('bool')\n",
    "    else:\n",
    "        train_data[col] = train_data[col].astype('category')\n",
    "\n",
    "# apply to test data\n",
    "for col in test_data.columns:\n",
    "    inferred = infer_column_dtype(test_data[col])\n",
    "    if inferred == 'numeric':\n",
    "        test_data[col] = pd.to_numeric(test_data[col], errors='coerce')\n",
    "    elif inferred == 'datetime':\n",
    "        test_data[col] = pd.to_datetime(test_data[col], errors='coerce')\n",
    "    elif inferred == 'boolean':\n",
    "        test_data[col] = test_data[col].astype('bool')\n",
    "    else:\n",
    "        test_data[col] = test_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff906dec-2f23-4cb9-8e63-d99ecf391d49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Train a forecast model\n",
    "The function `model_training` performs the following steps:\n",
    "\n",
    "1. Load the training data\n",
    "2. Set model parameters\n",
    "3. Create train-test split\n",
    "4. Train the model\n",
    "5. Evaluate the model's performance on the validation dataset\n",
    "6. Fine-tune the model parameters for optimal performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a694528-29d0-4ecb-a32c-fc202bce9fab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog(log_input_examples=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61b2a22b-e0ca-4ac3-93c1-bef754015d6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using the prepared dataset, we perform hyperparameter tuning of an XGBoost regressor using the Optuna TPESampler. For our hyperparameter set we configure the parameters in params."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad6c2874-5359-47ab-80ab-e77bf45baf6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# &#x270D;\n",
    "Running the training typically takes some time. To reduce the waiting time for the exercise we reduce the variable `<N_TRIALS>` to the value `5`, and sacrifice on the model qualtity and prediction accuracy.\n",
    "The `n_trials` specifies the number of different hyperparameter combinations Optuna will try. The training will take approximately 10 min. \n",
    "\n",
    "Remark: to arrive a better model quality, we recommend to set the value to `50`, which lead to a training duration of approximately 1h. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab0a57bf-c001-4de8-b61c-00b289d5b6a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def model_training(trial: optuna.trial.Trial, X: pd.DataFrame, y: pd.Series):\n",
    "    # Convert unsupported data types\n",
    "    X = X.copy()\n",
    "    for col in X.select_dtypes(include=['category', 'datetime64[ns, UTC]']).columns:\n",
    "        if X[col].dtype.name == 'category':\n",
    "            X[col] = X[col].astype('category').cat.codes\n",
    "        elif X[col].dtype.name == 'datetime64[ns, UTC]':\n",
    "            X[col] = X[col].astype('int64')  \n",
    "\n",
    "    params = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-2, 3e-1, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 10.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = XGBRegressor(**params, enable_categorical=True, n_jobs=-1, early_stopping_rounds=10)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=False\n",
    "    )\n",
    "    preds = model.predict(X_valid)\n",
    "    mse_score = mean_squared_error(y_valid, preds)\n",
    "    mape_score = mean_absolute_percentage_error(y_valid, preds)\n",
    "    r2_metric = r2_score(y_valid, preds)\n",
    "    return mse_score\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),\n",
    ")\n",
    "study.optimize(lambda trial: model_training(trial, train_data, train_target), n_trials=<N_TRIALS>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "994c1e9b-eaf3-4022-b174-4a5cdd959b05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Apply hyperparameter optimization\n",
    "Hyperparameter optimization is the process of finding the best set of hyperparameters for a machine learning model to improve its performance. Hyperparameters are the settings or configurations that are not learned from the data during training. Instead, they are set before the training process begins. Examples include:\n",
    "\n",
    "- Learning rate\n",
    "- Number of layers in a neural network\n",
    "- Number of trees in a random forest\n",
    "- Regularization strength\n",
    "- Batch size\n",
    "\n",
    "The choice of hyperparameters can significantly affect a modelâ€™s accuracy, generalization, and training time. Poor choices can lead to underfitting, overfitting, or inefficient training.\n",
    "\n",
    "Common optimization techniques:\n",
    "- Grid Search: Try all combinations from a predefined set of values.\n",
    "- Random Search: Randomly sample combinations from the hyperparameter space.\n",
    "- Bayesian Optimization: Use probabilistic models to predict which hyperparameters might perform best.\n",
    "- Gradient-based Optimization: Use gradients to adjust hyperparameters (less common).\n",
    "- Evolutionary Algorithms: Use genetic algorithms to evolve better hyperparameter sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0899c774-60ab-4831-8ab8-c23e7b5890b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Show Plots\n",
    "Next we will have a look at the optimization plots and check which of the parameters work best for our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0c93633-3c0a-4a53-bdfd-48756b06e2da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f26b158-bc62-4530-805c-8422b11210c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ov.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e02b66d-b7cd-489a-b585-b6587cf5dc5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ov.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a8ae1df-246c-401d-8454-cca808248cd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ov.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75b9fcb9-d4e6-4b5e-a8f5-9e7b7fede259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Retrieve Optimal Parameters\n",
    "To retrieve the best parameters for our final model you can run the following code and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "490f8e3a-184f-47a7-882c-77c3de5de259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best MSE:\", study.best_value)\n",
    "print(\"Best params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bb64cba-1ee3-4424-af0d-1a7f21b564a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Fit Model with optimized parameters\n",
    "Now we will fit the model using the preferred parameters and finally register the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81ca4698-28ed-48f0-ae5b-b61201dd81e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert datetime column to numerical format\n",
    "# train_data['__TIMESTAMP'] = train_data['__TIMESTAMP'].astype('int64')\n",
    "# test_data['__TIMESTAMP'] = test_data['__TIMESTAMP'].astype('int64')\n",
    "\n",
    "# Ensure categorical columns are properly encoded\n",
    "categorical_columns = train_data.select_dtypes(include=['category']).columns\n",
    "train_data[categorical_columns] = train_data[categorical_columns].apply(lambda x: x.cat.codes)\n",
    "test_data[categorical_columns] = test_data[categorical_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Delay_Prediction_Training\") as run:\n",
    "    final_xgbmodel = XGBRegressor(\n",
    "        **study.best_params,\n",
    "        enable_categorical=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    final_xgbmodel.fit(\n",
    "        train_data,\n",
    "        train_target,\n",
    "        verbose=False\n",
    "    )\n",
    "    predictions = final_xgbmodel.predict(test_data)\n",
    "    mse = mean_squared_error(test_target, predictions)\n",
    "    r2_metric = r2_score(test_target, predictions)\n",
    "    mape_score = mean_absolute_percentage_error(test_target, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12ee12e6-0c9b-4977-bf36-db2956ad31e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. Register and persist trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ac05c0f-b288-437c-add0-4a6a66b3a1f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trained_model = mlflow.register_model(f\"runs:/{run.info.run_id}/model\", \"delay_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "042b4bb3-8042-4e11-85be-71177299925d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# &#x270D;\n",
    "Please set the alias for the trained model with `prod` by replacing the value `<ALIAS>` accordingly. Using an alias makes it easier to retrieve and load the trained model in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "264e3c97-4ca8-40bb-956f-dd94747a25b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow_client = mlflow.MlflowClient()\n",
    "mlflow_client.set_registered_model_alias(name=trained_model.name, alias=\"<ALIAS>\", version=trained_model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f7c7c0d-921b-4007-8945-43c7cc3d18b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When executed successfully, you should be able to find the trained model `delay_prediction` in the Unity Catalog under your created SCHEMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cff930fe-69cf-4672-b2fe-69b1102cf9ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![delay_prediction_model.png](../../images/delay_prediction_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "124870cf-2820-4f24-96fd-0ef8ba4b37e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7791789125133195,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Payment_Delay_Training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
