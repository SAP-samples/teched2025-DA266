{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "263402ab-2336-474c-913c-6949d60e5e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Payment Delay Explain\n",
    "While [SHapley Additive exPlanations (SHAP) values](https://shap.readthedocs.io/en/latest/index.html) offer a powerful explanation of the prediction for data scientists, they can be difficult to interpret directly for business users. In this notebook we will use SAP AI Foundation services for Large Language Model (LLM) to intepret the prediction results in natural language. \n",
    "\n",
    "We demonstrate this through the example of [SAP AI Core Orchestration Service](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/orchestration-8d022355037643cebf775cd3bf662cc5?locale=en-US), which provides harmonized access to a wide range of frontier AI / LLM models. The orchestration service will be exposed as an MLflow model, for fully integrated downstream processing in SAP Databricks.\n",
    "\n",
    "These are the steps for the exercise:\n",
    "\n",
    "1. Install and import packages\n",
    "2. Load prediction data and SHAP Values\n",
    "3. Define Explanation Model\n",
    "4. Run Explanation Model\n",
    "5. Validate explanation results\n",
    "6. Persist explanation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a8684e8-ae20-4d64-ac31-892ef3dce4c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prerequisites\n",
    "> [!IMPORTANT]\n",
    "> This step has already been done by the administrator. However, if you need to do it on you own you can follow the steps described here to create a secret scope for secure access of SAP Cloud SDK for AI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "950cc051-3fc7-48cc-9748-c42c321d14cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To securely store and access SAP AI Core credentials from within SAP Databricks, create a Databricks secret(refer to [Databricks documentation on creating secret scopes](https://docs.databricks.com/aws/en/security/secrets)). \n",
    "\n",
    "Then, store the following access parameters as case-sensitive key-value pairs within this scope, as they are [defined in the documentation of the generative AI SDK](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/README_sphynx.html#environment-variables):\n",
    "\n",
    "- AICORE_BASE_URL\n",
    "- AICORE_AUTH_URL\n",
    "- AICORE_CLIENT_ID\n",
    "- AICORE_CLIENT_SECRET\n",
    "- AICORE_RESOURCE_GROUP\n",
    "\n",
    "Setting these credentials as environment variables allows the SAP Cloud SDK for AI (Python) to seamlessly authenticate and interact with the SAP AI Core orchestration service within the Databricks runtime. The SAP Cloud SDK for AI (Python) automatically manages the configuration and deployment of orchestration service endpoints and the desired Large Language Models (LLMs) upon initial use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a739e220-446b-4ca2-b968-2ab414624101",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Install and import packages\n",
    "In the next few cells, we will install and import the required packages. Please make sure, that we use the right versions of the libraries. While SAP AI Core capabilities are exposed via a REST API (see the [documentation on the SAP Business Accelerator Hub](https://api.sap.com/package/SAPAICore/rest)), this guide leverages the SAP Cloud SDK for AI (Python) to simplify consumption within Databricks notebooks. This SDK [sap-ai-sdk-gen](https://pypi.org/project/sap-ai-sdk-gen/) is free for download from PyPI and is documented on the [SAP Help Portal](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66b87703-9de9-478a-b310-e6ab0363cc95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install \"sap-ai-sdk-gen[all]\"\n",
    "%pip install \"mlflow[databricks]==3.1.3\"\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "629c7fce-a5f2-493b-b91a-8f3f3c05c130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import datetime, time\n",
    "from typing import List, Optional, Iterable, Union, Dict, Any\n",
    "import httpx\n",
    "import mlflow\n",
    "import gen_ai_hub as gen_ai_hub\n",
    "\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.exceptions  import OrchestrationError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c406a7cf-e798-4e29-88df-c5eb91137806",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Set Parameters\n",
    "Please replace the values `<CATALOG_NAME>` and `<SCHEMA_NAME>` with the specific values that match our use case and group. You can find the correct names by checking the **Unity Catalog** and look for the specific catalog and schema names: `uc_XXX`, `grpX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "823469f8-a96f-4ea5-ab3e-106342c19d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- CREATE CATALOG IF NOT EXISTS <CATALOG_NAME>;\n",
    "SET CATALOG uc_<CATALOG_NAME>;\n",
    "CREATE SCHEMA IF NOT EXISTS <SCHEMA_NAME>;\n",
    "USE SCHEMA <SCHEMA_NAME>;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6aeb0aa6-8b2c-438c-a53c-b693f765f695",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Load prediction data and SHAP Values\n",
    "In this step we load the prediction data including the SHAP values, that we would like to be interpreted. For that, \n",
    "replace `<DELAY_PREDICTION_SHAP_TABLE>` with the name of the table containing the delay prediction and SHAP values from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abb64207-f235-4485-a1e4-fb99ca1fd093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap_table_df = spark.read.table(\"<DELAY_PREDICTION_SHAP_TABLE>\")\n",
    "# display(shap_table_df.limit(10))\n",
    "print(f\"rows: {shap_table_df.count()}, columns: {len(shap_table_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b63834be-e0f6-4844-a64b-09634894abcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Reduce data for interpretation \n",
    " To reduce CPU and execution time of this exercise, we will filter the data that needs to be processed and interpreted by the LLM service. For that please set the `<NUMBER_OF_PREDICTIONS>` to the value `5`. These are the predictions with the highest delays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f354083c-1c4c-40e8-9bcb-143a0c131c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered_shap_table_df = shap_table_df.orderBy(\"delay_prediction\", ascending=False).limit(<NUMBER_OF_PREDICTIONS>).toPandas()\n",
    "display(filtered_shap_table_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e11922eb-8ead-4aa4-bbb6-b6ae06113efb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Define Explanation Model\n",
    "\n",
    "In the following we show how the additional capabilities of the SAP AI Core Orchestration Service can be leveraged in combination with MLflow in Databricks to generate our model explanations for the delay prediction. \n",
    "\n",
    "We use the **orchestration service of GenAI Hub via the SAP Cloud SDK for AI (Python)** as documented [here](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/orchestration-service.html).\n",
    "\n",
    "For the **integration into MLflow**, we provide a custom Python class derived from [mlflow.pyfunc.PythonModel](https://mlflow.org/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.PythonModel). A detailed explanation of the setup of the mlflow pyfunc PythonModel class can be found under the following [tutorial article](https://www.mlflow.org/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc/part2-pyfunc-components/).\n",
    "\n",
    "We aim at an integration that allows us to seamlessly track and manage LLM-powered explanation generation within the existing MLflow model lifecycle. With the [Langchain integration](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/gen_ai_hub.html#langchain-integration) of SAP GenAI hub for a direct integration into the MLflow ecosystem exists. This allows users to directly interact with the Databricks ecosystem and provides a possibility to cover the different aspects. Details of the **langchain autolog** functionality can be found [here](https://mlflow.org/docs/latest/genai/flavors/langchain/autologging#configure-autologging).\n",
    "\n",
    "The Python class is elaborated in the following with the methods\n",
    "\n",
    "- **\\__init\\__(…)** to instatiate the class\n",
    "- **load_context(…)** to instantiate the orchestration service\n",
    "- **predict(…)** to generate the verbal explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67cffb4b-b4ce-40f1-8923-1ecb894e2aa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from gen_ai_hub.orchestration.models.message import UserMessage\n",
    "import gen_ai_hub\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.message import UserMessage\n",
    "from typing import Dict, Any\n",
    "from mlflow.tracing import set_span_chat_messages\n",
    "\n",
    "class ExplanationModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self):\n",
    "        self.key_columns = []\n",
    "        self.llm_model = None\n",
    "        self.max_tokens = None\n",
    "        self.orchestration_service = None\n",
    "        self.feature_descriptions = None\n",
    "\n",
    "        # since the model is not saved and loaded, we need to load the context here\n",
    "        self.load_context()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5fffaa6-3610-46cb-a812-5bb85ac2cb2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### load context(...)\n",
    "\n",
    "The load_context method is used to establish the connection to an external service from the MLflow custom class. \n",
    "\n",
    "\n",
    "\n",
    "Instead of directly consuming a LLM for explanation, we use the [orchestration service](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/orchestration-service.html) of the Generative AI Hub because it offers a variety of features such as\n",
    "- the Prompt Registry for the management prompt templates,\n",
    "- the capability to mask personal or enterprise critical information\n",
    "- etc.\n",
    "\n",
    "In our exercise, we use a `gpt-4o-mini` model with a maximum token limit of `1000`. We also directly use Prompt Template of AI Core without the prompt registry functionality.\n",
    "\n",
    "For that we configure and create an instance of the SAP AI Core OrchestrationService using the following variables:\n",
    "\n",
    "- `<LLM_MODEL>` = gpt-4o-mini\n",
    "- `<MAX_TOKENS>` = 1000\n",
    "- `<SECRET_SCOPE>` = aicore_service_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22e55eb8-4530-47e3-84fd-f20c28ccca53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_context(self, context={}) -> None:\n",
    "        # Load the context from the mlflow context.\n",
    "        self.key_columns = [\"CompanyCode\", \"AccountingDocument\", \"FiscalYear\", \"AccountingDocumentItem\"]\n",
    "        self.llm_model = '<LLM_MODEL>'\n",
    "        self.max_tokens = <MAX_TOKENS>\n",
    "        secret_scope = '<SECRET_SCOPE>'\n",
    "\n",
    "        # set secret values as environment variables\n",
    "        for key in [\"AICORE_CLIENT_ID\", \"AICORE_CLIENT_SECRET\", \"AICORE_AUTH_URL\", \"AICORE_BASE_URL\", \"AICORE_RESOURCE_GROUP\"]:\n",
    "            os.environ[key] = dbutils.secrets.get(scope = secret_scope, key=key)\n",
    "\n",
    "        user_message_content = \"{{?prompt}}\"\n",
    "\n",
    "        orchestration_config = OrchestrationConfig(\n",
    "            template=Template(messages=[UserMessage(user_message_content)]),\n",
    "            llm=LLM(name=self.llm_model, parameters={\"max_tokens\": self.max_tokens})\n",
    "        )\n",
    "        self.orchestration_service = OrchestrationService(config = orchestration_config)\n",
    "\n",
    "ExplanationModel.load_context = load_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e166ddc-e1a0-4583-80a0-19e5f4a74025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### predict(...)\n",
    "For the predict method, we expect the `model_input` variable which receives the filtered shap values as input, as well as the `params` variable, which by default has the value `None`.\n",
    "\n",
    "For the overall output generation, we iterate over each individual role of the pandas dataframe. In the very first step, we extract the primary keys to return them in combination with the generated `delay_explanation`. The variables `shap_array` as well as the `delay_prediction` are used to fill the prompt template we used for the orchestration configuration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1aa493e-77b4-4d9d-a118-fd613a07a391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Once we have prepared the input of our data, we start our MLflow span to log our traces for the individual completion task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f91ff28-25dc-4823-b4c1-cd0f2d0a4526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict(self, model_input, params=None):\n",
    "        \"\"\" \n",
    "        Process the model inuput:\n",
    "        Expected input: Pandas DataFrame with \n",
    "        - key columns, with column names as listed in the list 'key_columns'\n",
    "        - columns 'shap_array', where each entry has the key 'column_name', 'column_description', 'column_value', 'shap_value' (all double)\n",
    "        - column 'delay_prediction'\n",
    "        Generated output: Pandas DataFrame with \n",
    "        - key columns,\n",
    "        - column 'delay_prediction' (double), and \n",
    "        - colums 'delay_explanation' (string)\n",
    "        \"\"\"\n",
    "        \n",
    "        model_output = []\n",
    "        rows = json.loads(model_input.to_json(orient='records'))\n",
    "\n",
    "        for row in rows:\n",
    "\n",
    "            row_result = {}\n",
    "            for key in self.key_columns:\n",
    "                row_result[key] = row[key]\n",
    "\n",
    "            row_result[\"delay_prediction\"] = row[\"delay_prediction\"]\n",
    "\n",
    "            template_values = []\n",
    "            prompt = self.build_prompt(row)\n",
    "            template_values.append(TemplateValue(name=\"prompt\", value=prompt))\n",
    "\n",
    "            '''\n",
    "            Once we have prepared the input of our data, we start our MLflow span to log our traces for the individual completion task. We name the span shap_explanation and use the span type of LLM. Within the MLflow span, we populate our orchestration model with the respective parameters and provide those as an input referencing the service instance  self.orchestration_service. When capturing the output, we store the orchestration result in the variable orchestration_result. To allow the logging of the system and user messages within mlflow, we extract those from the orchestration service for the individual run.\n",
    "            '''\n",
    "            with mlflow.start_span(name=\"shap_explanation\", span_type=\"LLM\") as span:\n",
    "\n",
    "                span.set_inputs(row)\n",
    "                try:\n",
    "                    orchestrationResponse = self.orchestration_service.run(template_values=template_values)\n",
    "                    orchestration_result = orchestrationResponse.orchestration_result\n",
    "                    \n",
    "                    choice = orchestration_result.choices[0]\n",
    "                    completion = choice.message.content\n",
    "                    row_result[\"delay_explanation\"] = completion\n",
    "                    messages = [{\"role\": message.role.value, \"content\": message.content} for message in orchestrationResponse.module_results.templating]\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": completion})\n",
    "                    set_span_chat_messages(span, messages)\n",
    "                    span.set_attributes({\"model_name\": self.llm_model, \"max_tokens\": self.max_tokens})\n",
    "                    span.set_outputs({\"prompt\": prompt, \"delay_explanation\": completion})\n",
    "\n",
    "                except OrchestrationError as error:\n",
    "                    model_output.append(error.message)\n",
    "                    span.set_outputs({\"ERROR\": error.message})\n",
    "\n",
    "\n",
    "                model_output.append(row_result)\n",
    "        \n",
    "        \n",
    "        pd_model_output = pd.DataFrame.from_records(model_output)\n",
    "        return pd_model_output\n",
    "    \n",
    "ExplanationModel.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5560eec-4df9-4d78-bd88-c7260ee46cc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In this exercise we focus on the five features with the highest abolute SHAP values, which we filter out by replacing the variable \n",
    "`<NUMBER_FEATURES>` with the value `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "153aa41e-2f05-4aee-b48d-8d20df60f6e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt(self, row: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        We construct the prompt from \"shap_array\" as a dynamic set of parameters.\n",
    "        \"\"\"\n",
    "        # We focus on the five features with the highest abolute SHAP values\n",
    "        number_of_features = <NUMBER_FEATURES>\n",
    "        shap_value_array = sorted( row[\"shap_array\"], key = lambda x: (abs(x[\"shap_value\"])), reverse=True)[:number_of_features]\n",
    "        feature_descriptions_md = \"\"\n",
    "        feature_values_md = \"\"\n",
    "        shap_values_md = \"\"\n",
    "\n",
    "        for i in range(number_of_features):\n",
    "            shap_array_item = shap_value_array[i]\n",
    "            feature_descriptions_md += f\"- '{shap_array_item['column_name']}': {shap_array_item['column_description']}\\n\"\n",
    "            feature_values_md +=  f\"- Value of '{shap_array_item['column_name']}': {shap_array_item['column_value']}\\n\"\n",
    "            shap_values_md += f\"- SHAP value for '{shap_array_item['column_name']}': {shap_array_item['shap_value']} days\\n\"\n",
    "\n",
    "\n",
    "        prompt = \"You are a data scientist who explains predictions of a business artificial intelligence model.\\n\"\n",
    "        prompt += \"The model predicts the expected delay for a payment.\\n\"\n",
    "\n",
    "        prompt += \"\\nThe following payment attributes are relevant for the prediction:\\n\"\n",
    "        prompt += feature_descriptions_md\n",
    "\n",
    "        prompt += \"\\nValues of these payment attributes:\\n\"\n",
    "        prompt += feature_values_md\n",
    "\n",
    "        prompt += \"\\nSHAP values for the attribute:\\n\"\n",
    "        prompt += shap_values_md\n",
    "\n",
    "        #TODO: add confidence etc\n",
    "\n",
    "        prompt += f\"\\nThe SHAP value for a feature decribes to what amount the predicted delay of {row['delay_prediction']} days deviates from the average value. A negative SHAP value for a feature means that the feature value reduces the prediction below average, while a positive value means that the feature value increases the prediction above average.\\n\"\n",
    "        prompt += \"Your task is to explain this specific prediction in a concise manner to a business person who is not a data scientist and who wants to understand which features are relevant for the prediction.\"\n",
    "        prompt += \" Do not mention the SHAP values in your explanation. You can use the feature values.\"\n",
    "\n",
    "        return prompt\n",
    "    \n",
    "ExplanationModel.build_prompt = build_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "737e0cc6-1c73-4dc7-921e-c90254911741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Run the explanation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1bbfb35-8efb-4d23-b217-19e1d6bb1cb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17fcb05b-6dcd-4817-a793-6ee6c5a4b550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Replace the variable `<FILTERED_SHAP_TABLE_DF_NAME>` with the name of the filtered dataframe, on which we want to apply the LLM explanation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "096c3768-a4b2-40e1-a767-7444f8f57cf9",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1759236311734}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "explanation_model = ExplanationModel()\n",
    "explanation_output = explanation_model.predict(<FILTERED_SHAP_TABLE_DF_NAME>)\n",
    "\n",
    "display(explanation_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a171a9d5-9ac1-4f37-923a-61a62bb98028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Validate the explanation results\n",
    "\n",
    "When executed successfully, you should be able to see the MLflow Trace UI. There you will find all logged information well organized for review:\n",
    "1. The _explanation_output_ table\n",
    "    - containing 5 records\n",
    "    - each record has a the column *delay_explanation*, where the LLM result is stored\n",
    "2. The MLflow Trace UI\n",
    "    - The tab _Chat_ contains all the messages we logged during the execution. Here you can find in the `Assistant` section the LLM explanation.\n",
    "    - The tab _Inputs/Outputs contains the Inputs and Outputs for the explanation\n",
    "    - the tab _Attributes_ contains the parameters we set in the explanation model class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6023cb9a-78e2-42ff-b043-7f521814a5fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here is an example, how it looks like:\n",
    "![mlflow_logging.png](../../images/mlflow_logging.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2abedf74-8eb6-486d-974a-0a0a3ee0a56c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Persist explanation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fcf8b94-e78c-4c80-b627-a636a8c1bfd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bb2b924-1431-4db4-9978-cf6772f12784",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Replace the `<EXPLANATION_RESULT>` with the name of the explation output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4fcb4ff-3c85-4fed-b228-91f6e0a4411d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_explanation_df = spark.createDataFrame(<EXPLANATION_RESULT>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07e48b5c-3955-4495-9820-74cd3429c07e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We persist the explanation results into a table. For the replace the `<PREDICTION_EXPLANATION_TABLE_NAME>` with `delay_prediction_explanation`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e05b4924-ba5e-46cd-8bc8-4af2ce2c5c29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_explanation_df.write.format(\"delta\").\\\n",
    "    mode(\"overwrite\").\\\n",
    "    option(\"delta.enableChangeDataFeed\", \"true\").\\\n",
    "    option(\"delta.enableDeletionVectors\", \"false\").\\\n",
    "    saveAsTable(\"<PREDICTION_EXPLANATION_TABLE_NAME>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aed712c4-7fe3-49e3-86c4-41b8f58a3285",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To be able to share later the table as data product, the following requirements should be fulfilled:\n",
    "- table has primary keys \n",
    "- DeletionVectors = disabled\n",
    "- ChangeDataFeed = enabled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94471288-dc62-44e0-8d8e-93eb851ac396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "ALTER TABLE <PREDICTION_EXPLANATION_TABLE_NAME> SET TBLPROPERTIES (\n",
    "  delta.enableChangeDataFeed = true,\n",
    "  delta.enableDeletionVectors = false\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5956681829211564,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Payment_Delay_Explain",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
