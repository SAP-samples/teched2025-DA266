{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6040cf01-05bf-4f7e-b428-4f97780c7d82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cash Liquidity Forecast\n",
    "For the Data Product Cash Flow we want to retrieve the prediction model and apply the data product to the trained model. This notebook shows an example workflow for the retrieval of a logged model and applying the CashFlow data product.\n",
    "This involves in total the following steps for the overall prediction:\n",
    "- Retrieve logged model from MLflow\n",
    "- Write prediction data to Delta Table\n",
    "- Expose Delta Table over Delta Share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8334ecc-1b0b-4c3f-b564-660558ca4e37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Install packages\n",
    "All necessary packages for this notebook are going to be outlined in the following notebook cell. In order to make sure that the results are reproducible, the following packages are going to be installed:\n",
    "- Mlflow: Used for tracking and storing of our model\n",
    "- AutoTS: Package allowing us to run different Time Series algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1404bb30-1720-4d8e-bf13-1b64a1686b04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow\n",
    "%pip install autots['additional']\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "968e06d0-59ae-4015-82d3-f1d42b10a5c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ec11107-2064-476e-8a64-767c2e1c11b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_trunc, sum, explode, expr\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1ef1863-15e8-4aca-9354-1cdb0d6f104c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup Spark Session and consume data product\n",
    "\n",
    "Please replace the values `<CATALOG_NAME>` and `<SCHEMA_NAME>` with the specific values that match our use case and group. You can find the correct names by checking the **Unity Catalog** and look for the specific catalog and schema names:`uc_XXX`, `grpX`. Additionally, please replace the value `<TIME_SERIES_TABLE_NAME>` with the according name. \n",
    "\n",
    "Please note: \n",
    "We adapted the code here to match our use case. Therefore, some of the lines are commented out and not needed. However, they can be useful for future applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f6075a8-072a-4da4-968d-a7474592cbbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- CREATE CATALOG IF NOT EXISTS <CATALOG_NAME>;\n",
    "SET CATALOG uc_cash_liquidity_forecast;\n",
    "-- CREATE SCHEMA IF NOT EXISTS <SCHEMA_NAME>;\n",
    "USE SCHEMA grp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e076d402-a963-4321-82c0-75e54fb02613",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "builder = SparkSession.builder.appName(\"cash_flow_forecasting\").getOrCreate()\n",
    "data = spark.read.table(\"prepared_cash_flow_time_series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05df601e-3e51-4ca7-9b10-a412ad62b8c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Time Series Forecasting\n",
    "We retrieve the model from the run from which we stored on MLflow for the Time Series training. After we retrieve the model from MLflow, we submit the spark dataframe to the predict function and retrieve the prediction from the function. After that we save the prediction data as a Delta Table and expose it over the Delta Share back to SAP Business Data Cloud.\n",
    "\n",
    "Please replace the value `<USERNAME>` with your user name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3e31453-ad65-4de2-8847-1b16405f747a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time_series_data = data.toPandas().astype({\"ds\": \"datetime64[ns]\", \"y\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72a917f7-effd-4286-8efb-5d9d60d69ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_experiment(\"/Users/<USERNAME>/Time Series Forecasting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e0a4c23-6cbe-429a-99fe-a1258605a28b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Retrieve MLflow model\n",
    "In order to get the model that we logged from our training procedure, we search in our MLflow experiment the last successful run ID and provide it to the mlflow functions in order to retrieve the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65240681-6df8-432d-9b67-e670d424ad88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "last_run = mlflow.search_runs(order_by=[\"start_time DESC\"])\n",
    "run_id = last_run[last_run[\"status\"] == \"FINISHED\"][\"run_id\"].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef897abd-d08b-4ba1-ae3e-758e547ec950",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logged_model = f'runs:/{run_id}/model'\n",
    "\n",
    "# Load model as a PyFuncModel\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "prediction = loaded_model.predict(time_series_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4f2244-727d-4157-8735-981b42871375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prediction = spark.createDataFrame(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fdf9c98-824e-4c2a-8352-194a1c194d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Creation of Cashflow Prediction table\n",
    "We create a prediction table that contains a constraint key consisting of the date and CompanyCode column. \n",
    "As the constraint key is unique over the complete Databricks catalog, please replace the constraint `<CONSTRAINT_NAME>` with an appropriate name for the constraint key. Additionally, choose a name for the prediction table and replace the value `<PREDICTION_NAME>` with it.\n",
    "\n",
    "To be able to install the data product to Datasphere later on, the following requirements need to be fulfilled:\n",
    "\n",
    "- **Primary keys** are defined \n",
    "- **DeletionVectors** = disabled\n",
    "- **ChangeDataFeed** = enabled \n",
    "\n",
    "The following code will take care of this and set `Primary Key` and adjust the settings for `DeletionVectors` and `ChangeDataFeed`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a3d59a3-8f4e-4e68-a54a-17e4684402d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prediction.write.format(\"delta\").\\\n",
    "    mode(\"overwrite\").\\\n",
    "    option(\"delta.enableChangeDataFeed\", \"true\").\\\n",
    "    option(\"delta.enableDeletionVectors\", \"false\").\\\n",
    "    saveAsTable(\"cashflow_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a7eecdc-b750-4d79-ad46-532721e7653a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "ALTER TABLE cashflow_prediction ALTER COLUMN `date` SET NOT NULL;\n",
    "ALTER TABLE cashflow_prediction ALTER COLUMN CompanyCode SET NOT NULL;\n",
    "ALTER TABLE cashflow_prediction ADD CONSTRAINT PK_DATE_COMP1 PRIMARY KEY (`date`, CompanyCode);\n",
    "ALTER TABLE cashflow_prediction SET TBLPROPERTIES(\n",
    "  delta.enableDeletionVectors = false,\n",
    "  delta.enableChangeDataFeed = true\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e3c2882-6862-47e0-986a-b0fbe1beca37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ALT VON HIER AN -> TO DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f3348c4-3cac-4283-b943-4f0f078763e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS cashflow_prediction_dp (\n",
    "  `date` TIMESTAMP NOT NULL,\n",
    "  CompanyCode STRING NOT NULL,\n",
    "  forecast DOUBLE,\n",
    "  upper_forceast DOUBLE,\n",
    "  lower_forecast DOUBLE,\n",
    "  CONSTRAINT PK_DATE_COMP PRIMARY KEY (`date`, CompanyCode)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d90831-242c-4f3e-b077-b5dde2a1c4bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "ALTER TABLE cashflow_prediction_dp SET TBLPROPERTIES(\n",
    "  delta.enableDeletionVectors = false,\n",
    "  delta.enableChangeDataFeed = true\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4a647256-9db8-4bd9-9457-15fbc921f9f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TO DELETE\n",
    "prediction.write.format(\"delta\").\\\n",
    "    #mode(\"overwrite\").\\\n",
    "    option(\"overwriteSchema\", \"true\").\\\n",
    "    option(\"delta.enableChangeDataFeed\", \"true\").\\\n",
    "    option(\"delta.enableDeletionVectors\", \"false\").\\\n",
    "    saveAsTable(\"cashflow_prediction_dp\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5370185177402475,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_Cash_Liqudity_Forecast",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
